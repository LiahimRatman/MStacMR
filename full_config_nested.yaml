device: 'cpu'
yolov5:
    model_name: 'checkpoints_and_vocabs/yolo_best.pt'
clip:
    model_name: 'ViT-B/32'
use_checkpoint: false
checkpoint_path: 'checkpoints_and_vocabs/model_best1.pth.tar'
training_params:
    train_annot_map_path: 'checkpoints_and_vocabs/full_dataset_train_mapa_good.json'
    train_img_emb_path: 'precomputed_embeddings/final_all_train_emb_CLIP_fixed.npy'
    train_ocr_emb_path: 'precomputed_embeddings/final_all_train_emb_CLIP_fixed.npy'
    eval_annot_map_path: 'checkpoints_and_vocabs/full_dataset_CTC_test_mapa_good.json'
    eval_img_emb_path: 'precomputed_embeddings/final_all_test_emb_CLIP_fixed.npy'
    eval_ocr_emb_path: 'precomputed_embeddings/final_all_test_emb_CLIP_fixed.npy'
    vocab_path: 'checkpoints_and_vocabs/f30k_precomp_vocab.pkl'
    learning_rate: 0.0002
    lr_update: 15
    num_epochs: 30
    batch_size: 128
    grad_clip: 2.0
    weight_retrieval_loss: 2.0
    weight_caption_loss: 1.0  
loss_params:
    margin: 0.2
    measure: 'cosine'
    max_violation: false  
image_encoder_params:
    image_embedding_dim: 512
    gcn_embedding_dim: 512
    num_ocr_boxes: 16
    ocr_box_dim: 300
    use_abs: false
    use_bn: false
    use_l2norm: false
    use_l2norm_final: false
    use_ocr_emb: true   
caption_encoder_params:
    caption_encoder_num_layers: 1
    caption_encoder_word_dim: 300  # caption embedding size
    caption_encoder_embedding_dim: 1024
caption_generator_params:
    dim_vid: 512  # было 2048, подозреваю, что это много
    dim_caption_generation_hidden: 512  # мб теперь надо поменять
    input_dropout_p_caption_generation_enc: 0.2
    input_dropout_p_caption_generation_dec: 0.2
    rnn_type_caption_generation_enc: 'gru'
    rnn_type_caption_generation_dec: 'gru'
    rnn_dropout_p_caption_generation_enc: 0.5
    rnn_dropout_p_caption_generation_dec: 0.5
    bidirectional_enc: false
    bidirectional_dec: false
    max_caption_len: 60
    dim_word_caption_generation: 300  # output of encoder decoder embedding size